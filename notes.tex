\documentclass[a4paper]{book}

%% Language and font encodings
\usepackage[english]{babel}
\usepackage[utf8x]{inputenc}
\usepackage[T1]{fontenc}

%% Sets page size and margins
\usepackage[a4paper,top=3cm,bottom=2cm,left=3cm,right=3cm,marginparwidth=1.75cm]{geometry}

%% Useful packages
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{graphicx}
\usepackage[colorinlistoftodos]{todonotes}
\usepackage[colorlinks=true, allcolors=blue]{hyperref}
\usepackage{listings}


\usepackage{mathtools}
\DeclarePairedDelimiter{\ceil}{\lceil}{\rceil}
\DeclarePairedDelimiter{\floor}{\lfloor}{\rfloor}

\newtheorem{proposition}{Proposition}
\newtheorem{lemma}{Lemma}
\newtheorem{corollary}{Corollary}
\newtheorem{theorem}{Theorem}

\title{Research Notebook}
\author{David R. MacIver}

\begin{document}

\maketitle

This is mostly a collection of research level material I am interested in.
It's something like a lab book,
something like a collection of papers I find interesting and want to make sure I remember and/or understand.

It is likely to be terribly organised.
It's primarily intended as a place for me to write stuff that is useful for me to have written down,
and only secondarily intended for public consumption.

It's also likely to be terribly formatted.
I'm not very good at \LaTeX.

\tableofcontents

\chapter{Literature Review}

This chapter is ``mostly'' literature review,
with the occasional sprinkling of my own work and ideas in it as they seem to fit.

\section{Inference of Finite Automata}

The paper I learned the most about this subject from was Rivest and Schapire's ``Inference of Finite Automata Using Homing Sequences''~\cite{DBLP:journals/iandc/RivestS93}.
This builds on Dana Angluin's classic L* search from ``Learning Regular Sets from Queries and Counterexamples''~\cite{DBLP:journals/iandc/Angluin87},
but extends it in several ways.

One very important feature of this paper which seems to be widely missed among people using L* search is that it significantly improves the algorithmic complexity of the number of queries that need to be performed.

Given some unknown language \(\mathcal{L}\) over an alphabet \(\mathcal{A}\),
L* search tries to find a deterministic finite automaton (DFA) representing that language given two oracles:
The first is a query oracle,
which allows you to test whether any string is in the language or not,
and the second is a counter-example oracle which allows you to test whether a given DFA is correct,
and if not presents a string for which it gives an incorrect answer.

It does this by constructing a deterministic finite automaton whose states are uniquely labelled by strings in some prefix-closed set \(S\),
and whose transitions are determined by some set of experiments \(E\).
Given a state \(s\) and a character \(c\),
the constructed automaton has a transition \(s \to t\) with \(c\) if \(sce \in \mathcal{L} \iff te \in \mathcal{L}\).
This works because of the following observations:

\begin{itemize}
\item Given \emph{any} deterministic finite automaton,
states can be uniquely labeled by a string that reaches that state from the origin.
By constructing these labels iteratively we can ensure that the set of labels used is prefix closed.
\item If two strings lead to the same state,
then any extension of them by the same string must also lead to the same state.
\item The same state cannot both be accepting and non-accepting.
\end{itemize}

Thus the experiments serve as a way of ``distinguishing'' two states:
If we ever observe that \(se \in \mathcal{L} \neq s'e \in \mathcal{L}\) then these can't lead to equivalent states.

This is the idea of the Myhill-Nerode theorem~\cite{nerode1958linear}\footnote{Confession:
I have not read the cited paper,
only the wikipedia page about it.
}.

L* search is essentially a way of learning the Myhill-Nerode automaton that results.
It proceeds in two parts:
The first tries to expand \(S\),
the second to expand \(E\).

Given a fixed set of experiments we first \emph{complete} the automaton:
For each \(s \in S\) and each \(c \in \mathcal{A}\) it tries to find a state in \(S\) that the current set of experiments thinks is equivalent to \(sc\).
If it finds one (and it cannot find more than one,
because we make sure to only enlarge \(S\) by adding inequivalent states to it),
we add a transition to that state.
If not,
we add \(sc\) to \(S\).

Once this is done,
we have an automaton that we hope matches \(\mathcal{L}\),
and we ask our counter-example oracle whether we're right.
If not,
we get a string which it gives the correct answer for.

This is where Angluin's original approach differs from Rivest and Schapire's.
Their observation builds on the surprisingly powerful idea that binary search has nothing to do with ordered sequences,
but is instead just about finding some point at which a function changes.\ 
i.e.\ if \(f(0) \neq f(n)\),
binary search finds some \(0 \leq i < n\) such that \(f(i) \neq f(i + 1)\).
If \(t\) is our counter-example then we can then use this to construct a new experiment to add to \(\mathcal{E}\) in \(O(\log(n))\) steps,
where \(n = |t|\).
We do this by taking \(f(i) = s_i t_{i+1} \ldots t_{n} \in \mathcal{L}\),
where \(t = t_1 \ldots t_n\) and \(s_i\) is the element of \(\mathcal{S}\) that labels the state that we are in after transitioning from the origin through
\(t_1, \ldots, t_i\).
We know that \(f(0) \neq f(n)\),
because \(f(0) = t \in \mathcal{L}\) and \(f(n) = s_n \in \mathcal{L}\) is the value that our automaton predicted for \(t \in \mathcal{L}\),
which was wrong.
This means that if \(i\) is our change point as above,
the transition we took from \(s_i \to s_{i + 1}\) was incorrect,
and \(t_{i + 2} \ldots t_n\) witnesses this fact,
so this is what we add to \(\mathcal{E}\).

In contrast,
Angluin's original algorithm tries to maintain \(\mathcal{E}\) as suffix-closed,
and as a result produces a much larger experiment set in a larger number of queries.

There is a lot of other information in this paper I need to go back and process at some point.
I should also write up its diversity based representation,
as I think it's a nice framing of this.

\section{DFA Minimization}

``Fast brief practical DFA minimization''~\cite{DBLP:journals/ipl/Valmari12} is a really nice paper about this,
although the experience of reading code golfed C++ to fit in a two column format wasn't a huge amount of fun.

It makes use of partition refinement,
applied to not just the states but the transitions,
beginning with a very coarse paritition that treats everything as equivalent and then progressively refining the partition whenever it finds an inconsistency.

One thing I thought was interesting about it is the core algorithm \emph{looks} like one you should have to iterate to a fixed point,
but actually it completes in a single run.

\section{Coupon Collecting and Sundry}\label{sec:coupons}

I've become interested in the non-uniform coupon collector problem recently,
which takes the following form:

Given \(X\) taking values in \(\{1, \ldots, n\}\) with \(P(X = i) = p_i > 0\),
if we have infinitely many independent copies \(X_i\) of \(X\),
and \(T = \min\limits_k |\{X_1, \ldots, X_k\}| = n\) (i.e. \(T\) is the first point we have seen every value at least once)
what is \(E(T)\)?

I proved some interesting lower bounds on this in terms of expectation that I haven't seen elsewhere but are probably not novel (I may add them in here later),
but more importantly ``Birthday Paradox, Coupon Collectors, Caching Algorithms and Self-Organizing Search''~\cite{DBLP:journals/dam/FlajoletGT92} is a really nice paper about this.

It takes the observation that this and many similar problems can be framed in terms of regular languages,
and that by using standard constructions of generating functions for regular languages,
you can more or less automate the calculation of their expected value (for values of ``automate'' that include calculating some potentially nasty integrals).

\section{Sandsifter}

Sandsifter~\cite{sandsifter} is a really neat trick that tries to find interesting hidden behaviour on x86 by just executing all the instructions and seeing what happens
(for values of ``seeing what happens'' that includes e.g.\ differential testing).
This seems infeasible:
Instructions may be up to 15 bytes long and there's no way to just try all \(256^{15} \approx 10^{36}\) such byte strings.

But it turns out that it's not!
The reason is that although they may be that long,
the instruction set is \emph{prefix-free}---no
instruction is a prefix of another.

This means that the following algorithm enumerates the entire instruction set:

\begin{enumerate}
\item Start from an all-zero buffer of 15 bytes.
\item Repeatedly execute the current buffer and see how many bytes are consumed.
\item Zero everything after the last byte read and increment the last byte read (handling overflow by setting it to zero and incrementing the previous one)
\item Stop when we have executed an instruction where every executed byte was 255.
\end{enumerate}

Because even though \emph{some} instructions are 15 bytes long \emph{most} aren't,
and in fact there turn out to be only about \(100,000,000\) instructions.

The only problem that remains is how to determine how many bytes were read given an x86 instruction.
This isn't something that the CPU tells you.
The answer is really neat:
Put the instruction right before a page boundary and watch to see if you trigger a fault when executing it!
If you do, then the instruction tried to read off the end of the page.
By sliding the position of the instruction around you can then find the smallest prefix that does not trigger a page fault.

\section{Parsing with Derivatives}

Parsing with derivatives\cite{DBLP:conf/icfp/MightDS11, DBLP:conf/pldi/0001HM16} is a really neat concept about how you can use laziness and meomization to extend the Brzozowski Derivative to context free languages,
essentially building up an infinite state automaton lazily as you traverse it.

I'm quite interested in applying this to the generation of objects in context free grammars,
but so far mostly just haven't---some
initial prototypes were reasonably promising but have never really manifested into anything very interesting.

One place this \emph{does} get used in Hypothesis is that the improved fixed point calculations in~\cite{DBLP:conf/pldi/0001HM16} are how Hypothesis calculates various properties of strategies which may recursively refer to each other.

\section{Boltzmann Sampling}

Given some combinatorial class of objects \(\mathcal{C}\) with a notion of size,
we might want to sample from it in such a way that any two objects with the same size occur with the same probability.
Boltzmann Samplers are a class of samplers which have this property and are amenable to mostly automated constructions.

The idea is that we consider the generationg function \(f(z) = \sum\limits_n z^n C_n\),
where \(C_n =  |\{c \in C: |c| = n\}|\}\),
so the coefficient of \(z^n\) is the number of elements of \(\mathcal{C}\) with size \(n\).

The Boltzmann samplers for \(\mathcal{C}\) are then a family of samplers with parameter \(z\) which pick an element of size \(n\) with probability \(z^n \frac{C_n}{f(z)}\).

The nice thing about this is that they combine well.\ 
e.g.\ if we have two disjoint classes of \(\mathcal{C}\) and \(\mathcal{C}'\) then we can construct a Boltzmann sampler for \(\mathcal{C} \cup \mathcal{C}'\) as a weighted choice between the Boltzman samplers for each,
picking from \(\mathcal{C}'\) with probability \(\frac{f'(z)}{f(z) + f'(z)}\).

A neat thing I have observed\cite{falbs} that probably isn't novel but that I haven't seen elsewhere is that given a regular language expressed as a deterministic finite automaton
(e.g.\ by using derivatives!)
you can automatically calculate a Boltzmann sampler for it using symbolic linear algebra
(or non-symbolic linear algebra if you fix the parameter up front).

The similarity of this paper to~\cite{DBLP:journals/dam/FlajoletGT92} is probably not accidental given that they have an author in common---both
are about using generating functions of regular languages to simplify some natural probabilistic problem through semi-automatic constructions.

\section{Fault Independence}

A nice set of papers starting from ``An Experimental Evaluation of the Assumption of Independence in Multiversion Programming''~\cite{DBLP:journals/tse/KnightL86}.

Key ideas:

\begin{itemize}
\item We want to see if multiple independent implementations of the same spec tend to fail in the same way.
\item Get a number of different people to implement the spec.
\item Then feed their implementations a million random inputs designed to look like a ``realistic workload'' and see if the inputs on which they fail are statistically independent.
\end{itemize}

Spoiler alert: They're not.

I haven't read the paper in detail yet,
but I \emph{have} read ``A reply to the criticisms of the Knight \& Leveson experiment''\cite{knight1990reply} which as well as being an intersting summary of the results is an absolutely glorious takedown.

As well as really liking the empiricism of this work,
one reason I'm interested in it is that a lot of the testing literature's focus on differential testing should be considered to have a fairly big hole down the middle as a result of this work---if everyone is making the same mistakes,
then differential testing won't pick this up,
and if mistakes are non-independent then the probability of this happening may be much larger than expected.

\section{Coverage Guided Fuzzing}

I need to do more research on this before I have anything intelligent to say about it,
but here are some things I think are neat ideas.

American Fuzzy Lop (AFL)~\cite{AFL} is of course kinda a big deal in this space.
There's quite a lot of literature on extending it,
though I'm not wholly convinced by it.

Nezha~\cite{DBLP:conf/sp/PetsiosTSKJ17} has the core idea that if you're doing differential testing between a bunch of different versions of something then maybe you should prioritise things that exhibit differences in behaviour!
It starts from some measurement \(\delta(x, s)\) taking an input and an SUT and returning some label for it,
then when doing differential testing between \(s_1, \ldots, s_n\) you can associate with an input \(x\) the profile \(\delta(x, s_1), \ldots, \delta(x, s_n)\).
Any particular value of this profile is not ``intrinsically'' interesting,
but the fact that two different inputs give a different profile indicates that the SUTs are exhibiting some difference in behaviour.
The important part of this is that they can do this without showing up any particularly novel behaviour in any one SUT!\@
I have not looked over their claims of its efficacy in any detail,
but it's an interesting idea.

Cause Reduction~\cite{DBLP:journals/stvr/GroceAZCR16} is the idea,
dear to my heart,
that you can apply test case reduction to many other problems,
not just bugs.
In particular you can apply it to coverage targets!
In this case they applied it mostly to coarse grained coverage targets (lines, branches, etc),
but I'm also interested in what happens with more fine grained ones.

\chapter{Miscellaneous Sums and Integrals}

The following came up in~\cite{DBLP:journals/dam/FlajoletGT92} as ``well known''.
It wasn't well known to me,
so I felt obliged to calculate it.
I'm not sure the process was enlightening enough to be worth it.

\begin{proposition}
\(\sum\limits_{q = 1}^m {(-1)}^{q - 1} {m \choose q} \frac{1}{q} = H(m)\)
\end{proposition}

\begin{proof}
\begin{align*}
\sum\limits_{q = 1}^m {(-1)}^{q - 1} {m \choose q} \frac{1}{q} &= \sum\limits_{q = 1}^m {(-1)}^{q - 1} {m \choose q} \int\limits_0^1 x^{q - 1} dx\\
&= \int\limits_0^1 \sum\limits_{q = 1}^m {(-1)}^{q - 1} {m \choose q} x^{q - 1} dx\\
&= \int\limits_0^1 -x^{-1} \sum\limits_{q = 1}^m {m \choose q} {(-x)}^q dx\\
&= \int\limits_0^1 -x^{-1} \left( \sum\limits_{q = 0}^m {m \choose q} {(-x)}^q - 1 \right)dx \\
&= \int\limits_0^1 -x^{-1} \left( {(1 - x)}^m - 1 \right)dx \\
&= \int\limits_0^1 {(1 - x)}^{-1} (x^m - 1) dx \\
&= \int\limits_0^1 \sum\limits_{n = 0}^\infty x^n (x^m - 1) dx \\
&= \sum\limits_{n = 0}^\infty \int\limits_0^1 x^n (x^m - 1) \\
&= \sum\limits_{n = 0}^\infty \frac{1}{n + m} - \frac{1}{n} \\
&= \lim\limits_{k \to \infty}  H(m) - \sum\limits_{n = k}^{m + k} \frac{1}{n + m}\\
&= H(m)\\
\end{align*}

Where the conversion of the infinite sum to the limit works because for every \(n \geq m\) the positive term in the summand cancels the negative term from the summand for \(n - m\),
and the final limit is calculated because \(0 \leq \sum\limits_{n = k}^{m + k} \frac{1}{n + m} \leq \frac{m}{n}\).
\end{proof}

\chapter{Miscellaneous Research Questions}

\section{Lower Bounds on Collecting Coupons}

Given the setup of Section~\ref{sec:coupons} for the non-uniform coupon collector problem,
here is an investigation into lower bounds on the expected waiting time for a complete set of coupons.
There are many like it, but this one is mine.

\begin{lemma}\label{lemma:couponpartition}
Let \(U_i\) be the set of distinct values seen by time \(i\) and for \(A \subseteq \{1, \ldots, n\}\) let \(S^A\) be the number of times we have seen \(X_i \in A\) before we have seen every value in \(A\).
Note that in terms of probabilities this is the same as being \(S\) for the conditional distribution \(X | X \in A\),
but it's important that these are actually using the same \(X_i\).

Then \(E(S|U_i = A) = i + \frac{1}{1 - P(X \in A)} E(S^{A^c})\)
\end{lemma}

\begin{proof}
Let \(L_0 = i\) and \(L_{k + 1}\) be the first time after \(L_k\) that \(X_{L_{k + 1}} \not\in A\).

Then \(E(S | S^{A^c} = m) = E(L_m)\).
But \(L_{k + 1} - L_{k}\) is geometrically distributed with parameter \(P(X \not\in A) = 1 - P(X \in A)\),
so \(E(L_{k + 1} - E_(L_k)) = \frac{1}{1 - P(x \in A)}\),
and so \(E(L_m) = i + \frac{m}{1 - P(x \in A)}\).
By applying conditional expectation we thus have \(E(S) = i + \frac{1}{1 - P(X \in A)} E(S^{A^c})\) as desired.
\end{proof}

This partition result also gives u

\begin{theorem}
\(E(S) \geq n H(n)\), with equality if and only if \(X\) is a uniform distribution.
\end{theorem}

\begin{proof}
We will do this by induction.
It is trivially true when \(n = 1\) because \(S = 1\) in that case.

By applying the previous lemma,
\(E(S | X_1 = i) = 1 + \frac{1}{1 - p_i} E(S^{{\{i\}}^c})\).

\(S^{{\{i\}}^c}\) has the same distribution as \(S\) for the conditional distribution of \(X | X \neq i\),
so in particular it has the same expecation.
Thus by our inductive hypothesis,
\(E(S^{{\{i\}}^c}) \geq n H(n)\) with equality if and only if this conditional distribution is uniform.

Let \(b_i = E(S^{{\{i\}}^c})\).
Then by conditional expectation,
\(E(S) = 1 + \sigma \frac{p_i}{1 - p_i} b_i \geq (n - 1) H(n) \sigma \frac{p_i}{1 - p_i} \).

This sum can be seen to be strictly minimized when \(p_i = \frac{1}{n}\),
which gives us \(E(S) \geq 1 + (n - 1) H(n) \frac{n}{n - 1}\) with equality if and only if \(X\) is uniform.

A simple induction shows that this term is equal to \(n H(n)\) and the result is proved.
\end{proof}

\begin{proposition}\label{prop:coupontail}
If \(p = P(X \geq m)\) then \(E(T) \geq \frac{n - m + 1}{p}\).
\end{proposition}

\begin{proof}
This is just the lemma applied to the very crude lower bound that \(E(S^A) \geq |A|\).
\end{proof}

\begin{proposition}\label{prop:couponestimate}
For any strictly increasing function \(f\) and \(1 \leq m \leq n\)
\(E(S) \geq \frac{f(m) (n - m + 1)}{E(f(X))}\).
\end{proposition}

\begin{proof}
This follows straightforwardly from the standard result that \(P(X \geq m) \leq \frac{E(f(X))}{f(m)}\) and Corollary~\ref{prop:coupontail}.
\end{proof}

\begin{theorem}
\(E(S) \geq \frac{2 {(k + 1)}^{-1} {(n + 1)}^{k + 1} - e (k + 1) {(n + 1)}^{k - 1}}{E(X^k)}\)
\end{theorem}

\begin{proof}
Let \(f(x) = x^k\) in Proposition~\ref{prop:couponestimate}.

Now, define \(g(x) = (n - x + 1) x^k\).
We'd like to find \(m \in \{1, \ldots, m\}\) that maximises \(g(m)\) to get the largest lower bound on \(E(S)\).

\begin{align*}
g'(x) &= (n - x + 1) k x^{k - 1} - x^k\\
&= (n + 1) k x^{k - 1} - (k + 1) x^k\\
&= \left( (n + 1) k - (k + 1) x \right) x^{k - 1}\\
&= \left( (n + 1) \frac{k}{k + 1} - x \right)(k + 1) x^{k - 1}\\
\end{align*}

So \(g'(x) = 0\) when \(x = x_{\max} = \frac{k}{k + 1} (n + 1)\).

Unfortunately we can't just plug in \(x_{\max}\),
because it might not be integral.
But we can find an integer \(1 \leq i_{\max} \leq n\) with \(|x_{\max} - i| \leq 1\).
\(|g'(y)| \leq (k + 1){(1 + x_{\max})}^{k - 1}\) for \(y\) between \(x_{\max}\) and \(i_{\max}\),
so

\(g(i_{\max}) \geq (n - x_{\max} + 1)x_{\max}^{k} - (k + 1){(1 + x_{\max})}^{k - 1}\)

\begin{align*}
(n - x_{\max} + 1)x_{\max}^{k} &= \frac{n + 1}{k + 1} {(n + 1)}^k {(1 + k^{-1})}^k\\
&= {(k + 1)}^{-1} {(n + 1)}^{k + 1} {(1 + k^{-1})}^k\\
&\geq 2 {(k + 1)}^{-1} {(n + 1)}^{k + 1} \\
\end{align*}

Where the latter bound comes from the fact that \(x \to {(1 + x^{-1})}^x\) is monotonic increasing.

\begin{align*}
{(1 + x_{\max})}^{k - 1} &= {(n + 1)}^{k - 1} {(1 + k^{-1})}^k \\
&\leq e {(n + 1)}^{k - 1}\\ 
\end{align*}

Thus we have \(g(i_{\max}) \geq 2 {(k + 1)}^{-1} {(n + 1)}^{k + 1} - (k + 1) e {(n + 1)}^{k - 1}\).
Plugging this in to the results of the previous corollary,
this gives us the desired result.

\end{proof}

\begin{corollary}
If \(X\) comes from some family of distributions such that \(E(X^k)\) is bounded as \(n\) varies,
then \(E(S) \geq O(n^{k + 1})\).
\end{corollary}

This bound is not quite tight,
and is missing a logarithmic factor.
A more involved calculation could ``easily'' recover it---we
simply dropped the factor of \(H(n - m + 1)\) in our initial approximation of how long it would take to fill all \(k \geq m\).

These bounds are particularly interesting because \(E(S)\) is independent under permutations of \(\{1, \ldots, n\}\),
and thus we may reorder the \(p_i\) values however we want before calculating these bounds.

\begin{theorem}
Let \(\sigma\) be a permutation of \(\{1, \ldots, n\}\).
If \(f\) is strictly increasing on \([1, n]\) then \(E(f(\sigma(X)))\) is strictly minimized when \(\sigma(i) < \sigma(j)\) implies \(p_i \geq p_j\).
\end{theorem}

\begin{proof}
Suppose that \(\sigma\) does not have this property.
Pick \(i, j\) with \(p_i < p_j\) and \(\sigma(i) < \sigma(j)\).
Now create \(\sigma' = (\sigma(i) \sigma(j)) \cdot \sigma\),
the permutation that first performs \(\sigma\) and then swaps \(\sigma(i)\) with \(\sigma(j)\).

Now:

\begin{align*}
E(f(\sigma'(X))) - E(f(\sigma(X))) &= p_i \sigma(j) + p_j \sigma(i) -  p_j \sigma(j) - p_i \sigma(i) \\
&= (p_j - p_i) (\sigma(i) - \sigma(j)) \\
&< 0\\ 
\end{align*}

Where the latter inequality follows because \(p_j - p_i > 0\) and \(\sigma(i) - \sigma(j) < 0\),
by our assumptions.
\end{proof}

\begin{theorem}
Let \(X\) be such that \(p_{i + 1} \leq p_i\),
and let \(f\) be a strictly increasing function on \(\{1, \ldots, n\}\)
Then \(E(f(X))\) is strictly maximized when \(X\) is the uniform distribution.
\end{theorem}

\begin{proof}
A similar argument as the previous theorem: Suppose we have \(i\) with \(p_{i + 1} < p_i\).
Write \(p_i = a + b, p_{i + 1} = a - b\),
where \(a = \frac{p_i + p_{i + 1}}{2}\) and \(b = \frac{p_i - p_{i + 1}}{2}\).
Then if \(X'\) results from replacing both \(p_i\) and \(p_{i + 1}\) with \(a\),
this will result in

\begin{align*}
E(X') - E(X) &= a f(i) + a f(i + 1) - (a + b) f(i) - (a - b) f(i + 1) \\
&= b (f(i + 1) - f(i)) \\
&> 0\\
\end{align*}

So whenever we have two adjacent probabilities that are not equal,
we can strictly increase the expectation by making them equal,
thus this expectation is maximized by the uniform distribution.

\end{proof}

Thus with any strictly increasing function \(f\),
once we have reorderd the values of \(X\) in this way we can regard \(E(f(X))\) as a measure of ``how far from uniform'' \(X\) is.

\section{Boltzmann Sampling of Levenshtein Automata}

\newcommand{\levlang}[2]{\mathcal{L} (#1, #2)}

Let \(\mathcal{A}\) be an alphabet.
To avoid triviality assume \(|\mathcal{A}| \geq 2\).

The Levenshtein distance of two strings \(u, v\) over \(\mathcal{A}\), \(d(u, v)\), is the length of the shortest path from \(u\) to \(v\) where a step in the path is either replacing a single character, deleting as ingle character, or inserting a single character.

The set of strings \(\levlang{u, n} = \{ v: d(u, v) \leq n \}\) is finite,
and so certainly regular,
but it even admits a fairly small DFA (this is not a new observation at all).

This means we should be able to calculate a Boltzmann sampler for it\cite{falbs}!

Can we do so efficiently?

We'll use the Brzozowski derivative to explore the structure of these languages.

Let \(b_L\) be the generating function of a language \(L\).

First: A crosscheck we can use is that the coefficients in the generating function must always be polynomials,
and the coefficients must be in \([|u| - n, |u| + n]\),
as any single step can only change the size by at most one,
so there are no strings of length outside that range to contribute to the generating function.

First,
two useful special cases:

\begin{proposition}
Now note that \(\levlang{\epsilon}{n}\) is the set of all strings of length at most \(n\),
so has generating function \(b_{\levlang{\epsilon}{n}}(z) = \frac{1 - {(|A|x)}^{n + 1}}{1 - |A| z}\).
\end{proposition}

\begin{proposition}
\(\levlang{v}{0}\) matches only \(v\),
so has \(b_{\levlang{v}{0}} = z^{|v|}\) 
\end{proposition}

\begin{theorem}
Let \(v = cu\) where \(c \in \mathcal{A}\),
and let \(\delta\) be the Brzozowski derivative.

\begin{itemize}
\item \(\delta(\levlang{v}{n}, c) = \levlang{u}{n}\).
\item \(\delta(\levlang{v}{b}) = \levlang{cu}{n - 1} \cup \levlang{u}{n - 1} \cup \delta(\levlang{u}{n - 1}, b)\)
\end{itemize}

\end{theorem}

\begin{proof}
If \(b = c\) there is nothing to do that we couldn't do later,
so we can just consume it and match the rest of the string,
thus \(\delta(\levlang{cu}{n}, c) = \levlang{u}{n}\).

If \(b \neq c\) then we can either delete \(b\) from the string,
meaning that the suffix must now be in \(\levlang{cu}{n - 1}\),
replace it with \(c\),
meaning that the suffix must now be in \(\levlang{u}{n - 1}\),
or insert \(c\),
which means that the remainder of the string \emph{including the current character},
must be in \(\levlang{u}{n - 1}\),
i.e.\ the suffix must be in \(\delta(\levlang{u}{n - 1}, b)\).
So \(\delta(v, b)\) is the union of these three possibilities.
\end{proof}

\begin{proposition}
Decompose \(v\) as \(v_1 \ldots v_m\) where each \(v_i\) consists of repetitions of a single character \(c_i\),
and the character in \(v_i\) is distinct from that in \(v_{i + 1}\).
Let \(n = |v|\) and suppose \(n > 0\).

Then \(b_{\levlang{v}{1}} = m z^{n - 1} + (1 + (|\mathcal{A}| - 1)n) z^{n} + ((n + 1) |\mathcal{A}| - n) z^{n + 1}\)
\end{proposition}

\begin{proof}
This is a relatively straightforward counting argument.

You can obtain a string of length \(n - 1\) only by deleting a single character,
but deleting any character inside \(v_i\) has the same effect,
so there are only \(m\) distinct deletions.

You can obtain a string of length \(n\) only by leaving the string unchanged or replacing a single character,
and each index admits \(|\mathcal{A}| - 1\) such replacements.

The calculation for \(n + 1\) is slightly harder.
Such a string must be obtained by an insertion,
but we must be careful not to overcount.

First,
we count all the insertions that just increase the length of one of the \(v_i\) by \(1\).
This gives us exactly \(m\) new strings.

Now, there are \(n + 1\) points we can insert at.
If these are interior to a \(v_i\)---that is,
it is between two characters of the same value---
then there are \(\mathcal{A} - 1\) possible values to insert (anything other than \(c_i\)),
but if it is the boundary then there are  \(\mathcal{A} - 2\) values---anything
other than \(c_i\) or \(c_{i + 1}\).

There are exactly \(m - 1\) points that are not interior---in
between each of the \(v_i\).

Thus there are \((m - 1)(|\mathcal{A}| - 2) + (n - m + 2)(|\mathcal{A} - 1|) = (n + 1) |\mathcal{A}| - m - n\).
Counting the insertions that expanded a \(|v_i|\),
this gives us a total of \((n + 1) |\mathcal{A}| - m - n\) as desired.
\end{proof}

In general I doubt the existence of a nice formula for this Boltzmann Sampler,
but the nice thing is that we can use the derivative method to simulate it lazily.
We can also use the above formula to simplify our calculations whenever we get down to a \(\levlang{v}{1}\) term.

\bibliography{references}{}
\bibliographystyle{acm}

\end{document}
