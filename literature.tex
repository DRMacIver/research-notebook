\input{./includes/preamble.tex}

\title{Literature Review for Hypothesis PhD}
\author{David R. MacIver}

\begin{document}

\maketitle

\tableofcontents

\chapter{Where are we going and what are we doing in this handbasket?}

NB:\ This literature review is very much a work in progress and is not really ready for public consumption.
It is and will be highly fragmented,
with large missing gaps and much of the bits that are here only in a temporary state that will later be reworked into other things.
Proceed with caution.

How to explain? How to describe? Even the omniscient viewpoint quails\cite{0812515285}.

Let me begin with some context.

The focus of my PhD is an open source project I wrote (and many others now also contribute to) called \emph{Hypothesis}.
Hypothesis was originally purely a Python library\footnote{\url{https://github.com/HypothesisWorks/hypothesis-python}},
but now also has a version for Ruby\footnote{\url{https://github.com/HypothesisWorks/hypothesis-ruby}}.
I will blur the distinction and simply refer to them all as ``Hypothesis''.

Hypothesis is a library in the spirit of QuickCheck\cite{DBLP:conf/icfp/ClaessenH00} for \emph{property-based testing}.
The distinguishing feature of such tools is that they make it easy for users to define tests that combine user-written specifications with some form of data generation.
Such tests assert properties that are intended to hold for an entire class of inputs,
although in practice only ever test on a finite number of inputs in any given run.

I do not propose to do an extensive review of the existing literature on QuickCheck,
for two main reasons.

The first is that it would frankly be redundant.
If you are interested in a detailed survey of QuickCheck and QuickCheck-related tools in the context of Haskell,
I refer you to Rudy Braquehais's recent PhD thesis\cite{matela2017tools},
where he ably summarizes it and a wide variety of related tools.

The second is that despite the shared lineage,
due to differing implementation strategies and contexts,
Hypothesis actually has comparably little in common with QuickCheck that they do not both share in common with a much broader area of testing research.

QuickCheck nevertheless provides the starting point for many of the \emph{problems} that I will motivate,
and where relevant I will of course first back to it and its descendants.

\chapter{Software Correctness in Practice}

Have you noticed that a lot of software is bad?
If you haven't,
let me break it to you gently:
A lot of software is bad.

Research on software correctness often begins with a grandiose discussion of this problem,
and how it's only going to get worse over time.
Typically the authors go on to suggest that their hot new research technique is the solution to it,
their (often very good!) research is duly published,
and the hot new research technique subsequently attracts exactly zero users in industry.

I propose that \emph{if we actually care about the problems that we claim to care about},
the two most critical questions in software testing research are the following:

\begin{enumerate}
\item Why is nobody using our stuff?
\item If they did, would it help?
\end{enumerate}

One possible answer to the first question comes from ``A Few Billion Lines of Code Later''\cite{DBLP:journals/cacm/BesseyBCCFHHKME10}.
They report on their experience of productionizing a static analyzer for C and C++,
and make the following observations:

\begin{enumerate}
\item ``in the research lab a few people check a few code bases; in reality many check many. The problems that show up when thousands of programmers use a tool to check hundreds (or even thousands) of code bases do not show up when you and your co-authors check only a few.''
\item ``in the lab the user's values, knowledge, and incentives are those of the tool builder, since the user and the builder are the same person. Deployment leads to severe fission; users often have little understanding of the tool and little interest in helping develop it''
\end{enumerate}

To put it more bluntly,
the tools we build probably don't work for most users,
and even when they do the users might not care enough for it to matter.

When we build tools we do so with a certain view of the world in mind---we
have a particular background and experience,
we have particular goals,
and we have a particular set of skills and knowledge.
But,
to use a term from user experience,
\emph{we are not the users},
and any belief that we might have that the users of our tools share that view of the world is a dangerous false consensus effect\cite{ross1977false},
where we are building tools to support a large number of like-minded individuals who simply don't exist.

\chapter{QuickCheck's friends and family}\label{chap:quickcheck}

QuickCheck was introduced back in 2000,
in ``QuickCheck: a lightweight tool for random testing of Haskell programs''\cite{DBLP:conf/icfp/ClaessenH00}.
It has since been ported to many languages\footnote{\url{https://hypothesis.works/articles/quickcheck-in-every-language/}},
with the most notable one being the commercial Erlang implementation\cite{DBLP:conf/erlang/ArtsHJW06}.

A test in QuickCheck looks something like the following:

\begin{lstlisting}[language=Haskell]
import Test.QuickCheck (quickCheck, (==>), Property)
import Data.List (elem, delete)

prop_remove :: [Int] -> Int -> Property
prop_remove ls x = elem x ls ==> not (elem x (delete x ls))

main = quickCheck prop_remove
\end{lstlisting}

In this test we test the property that given a list of integers and an integer,
with the integer contained in the list,
after removing the integer from the list it is not longer present.

A similar property expressed in Hypothesis would be:

\begin{lstlisting}[language=Python]
from hypothesis import given, assume
import hypothesis.strategies as st


@given(st.lists(st.integers()), st.integers())
def test_deleting(ls, i):
    assume(i in ls)
    ls.remove(i)
    assert i not in ls
\end{lstlisting}

When run, these tests both do the same thing:
They randomly generate a list of integers and an integer,
if the integer is contained in the list they continue the test,
otherwise they mark it as invalid.
Once they have found a sufficient number of valid test cases that did not fail (100 by default) the test stops.
If prior to that point they have found a counter-example to the property,
they begin a process of test-case reduction to attempt to produce a smaller, simpler, example.

The development of QuickCheck and its descendants in the context of Haskell has recently been very ably summarised in Rudy Braquehais's PhD thesis\cite{matela2017tools},
so I do not propose to go into QuickCheck in great detail,
but instead to situate it in the broader context of the software testing literature.

As a result I will take the liberty to be significantly more opinionated in my review of the subject.

The first piece of context to consider is that this combination of random testing and test-case reduction is at this point,
from a research point of view,
\emph{incredibly boring}.
Random testing and test case reduction are both very well studied subjects---in
the latter only since the original QuickCheck paper was published
(the original paper on the subject being of a comparable age to QuickCheck itself\cite{DBLP:conf/issta/HildebrandtZ00}),
but even at the time of publication Random testing was a very well known implementation technique (TODO:\ Citations).

The novel feature of QuickCheck was in fact nothing to do with the quality of its testing,
but that it provided a way of composing these generators together to make it easier to write arbitrary tests over arbitrary data types.

This is not intended as a slight on the authors of QuickCheck,
as they acknowledge this in the paper itself!

\begin{quote}
We have taken two relatively old ideas, namely specifications as oracles and random testing,
and found ways to make them easily available to Haskell programmers.
\end{quote}

Thus from the very beginning the basic question of QuickCheck's design has not been one of advancing the state of the art of software testing research,
but fundamentally a question of usability:
How can we make it easier for people to use these ideas?

Given this,
what happened next may surprise you:
The intervening period has consisted of users of QuickCheck and its descendants holding on to the rather bizarre belief that this sort of testing is in some way tied to functional programming.

For example,
consider the following quote from~\cite{matela2017tools}:

\begin{quote}
Although still useful,
property-based testing is a bit less useful in the realm of imperative programming languages as property-based testing
benefits from testing functions and modules that have no side-effects
\end{quote}

This is not to pick on the author of this quote specifically:
It is a notion I've personally heard many times,
this merely happens to be the most recent.

In one sense this claim is true:
It is much easier to test code that has no side-effects.
On the other hand,
it seems to ignore the fact that testing remains the most common tool for software correctness and is widespread in industry in almost every programming language,
but if anything is \emph{especially} common in dynamically typed imperative programming languages,
which according to this line of reasoning are the hardest to test.

\chapter{Teach me your human notion of software testing}\label{chap:purposesoftesting}

This chapter isn't written yet.
In this chapter I will argue that our notion of what testing is for is flawed:
Most testing cannot be about finding bugs,
because the overwhelming majority of software has no non-trivial bugs until a negotiation involving both the users and the authors of the software concludes that a particular behaviour is a bug.

\chapter{Speaking a test's language}\label{chap:testinglanguage}

This chapter isn't written yet.
This will be a little bit about explaining the implementation of Hypothesis,
and a lot about how this connects up to ideas from fuzzing, language inference, combinatorics (e.g. Boltzmann Samplers), and maybe search-based software testing.
It will also contain a test-case reduction subsection.

\chapter{A new and terrifying age of high quality software}\label{chap:conclusion}

This chapter isn't written yet.
It's basically a more entertaining name for ``Conclusion'',
with reference to the manifesto in the Hypothesis documentation.

\chapter{Unincorporated Material}

This chapter gathers papers that I must/should/could include in my review,
along with some notes on them,
but does not attempt to do any significant amount of synthesis.

\section{Must Haves}

\subsection{QuickCheck Papers}

The foundational paper for my work is of course ``QuickCheck: a lightweight tool for random testing of Haskell programs''\cite{DBLP:conf/icfp/ClaessenH00}.

There are a number of other papers worth referencing:

\begin{itemize}
\item ``Testing telecoms software with quviq QuickCheck''\cite{DBLP:conf/erlang/ArtsHJW06}
\item ``SmartCheck: automatic and efficient counterexample reduction and generalization''\cite{DBLP:conf/haskell/Pike14} is one of the few papers about improving QuickCheck's test case reduction,
so definitely worth including.
\end{itemize}

\subsection{Test Case Reduction Papers}

\begin{itemize}
\item ``Simplifying failure-inducing input''\cite{DBLP:conf/issta/HildebrandtZ00} is the delta-debugging paper that you have to cite if you ever write anything about test-case reduction.
\item ``One test to rule them all''\cite{DBLP:conf/issta/GroceHK17} is particularly relevant to Hypothesis because of the relationship between normalization and its shortlex-minimization goal.
\item ``Minimization of Randomized Unit Test Cases''\cite{DBLP:conf/issre/LeiA05} is a good justification for the combination of random test case generation and test-case reduction.
\end{itemize}

\section{Should Haves}

\begin{itemize}
\item ``Targeted property-based testing''\cite{DBLP:conf/issta/LoscherS17} is about how you can do what is basically hill climbing with restart to better test properties.
This is relevant mostly as an example of why it's nice to be able to extend with new operations on generated data.
\item ``Why is random testing effective for partition tolerance bugs?''\cite{DBLP:journals/pacmpl/MajumdarN18} is an interesting argument that random testing can and should work.
\item ``Partition Testing Does Not Inspire Confidence``\cite{DBLP:journals/tse/HamletT90} is a good argument that random testing is pretty OK.\ 
\item ``Behind Human Error''\cite{BehindHumanError} contains a lot of lucid discussion about error that I think is valuable for this sort of work.
\item ``An Experimental Evaluation of the Assumption of Independence in Multiversion Programming''\cite{DBLP:journals/tse/KnightL86}---a
lot of property-based testing is basically multiversion programming to do differential testing.
\item ``Software Testing Research: Achievements, Challenges, Dreams''\cite{DBLP:conf/icse/Bertolino07} (for a good survey of where software testing research is and wants to go, and some useful basic questions).
\end{itemize}

\section{Could Haves}

\begin{itemize}
\item ``Can a Machine Design?''\cite{doi:10.1162/07479360152681083} contains a really nice account of different modes of human/computer codesign,
and how having the computer make things for a human to correct is much less stressful than having the computer correct the human.
\item ``When and what to automate in software testing? {A} multi-vocal literature review''\cite{DBLP:journals/infsof/GarousiM16}---this
seems a natural fit.
\end{itemize}

\section{Really Want An Excuse To Haves}

As James Mickens puts it\cite{mickens2014saddest}:

\begin{quote}
``How can you make a reliable computer service?'' the presenter will ask in an innocent voice before continuing,
``It may be difficult if you canâ€™t trust anything and the entire concept of happiness is a lie designed by unseen overlords of endless deceptive power.''
The presenter never explicitly says that last part,
but everybody understands what's happening.
\end{quote}


\input{./includes/bibsection.tex}

\end{document}
