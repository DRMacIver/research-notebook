\chapter{Boltzmann Sampling}

Given some combinatorial class of objects \(\mathcal{C}\) with a notion of size,
we might want to sample from it in such a way that any two objects with the same size occur with the same probability.
Boltzmann Samplers are a class of samplers which have this property and are amenable to mostly automated constructions.

The idea is that we consider the generationg function \(f(z) = \sum\limits_n z^n C_n\),
where \(C_n =  |\{c \in C: |c| = n\}|\}\),
so the coefficient of \(z^n\) is the number of elements of \(\mathcal{C}\) with size \(n\).

The Boltzmann samplers for \(\mathcal{C}\) are then a family of samplers with parameter \(z\) which pick an element of size \(n\) with probability \(z^n \frac{C_n}{f(z)}\).

The nice thing about this is that they combine well.\ 
e.g.\ if we have two disjoint classes of \(\mathcal{C}\) and \(\mathcal{C}'\) then we can construct a Boltzmann sampler for \(\mathcal{C} \cup \mathcal{C}'\) as a weighted choice between the Boltzman samplers for each,
picking from \(\mathcal{C}'\) with probability \(\frac{f'(z)}{f(z) + f'(z)}\).

A neat thing I have observed\cite{falbs} that probably isn't novel but that I haven't seen elsewhere is that given a regular language expressed as a deterministic finite automaton
(e.g.\ by using derivatives!)
you can automatically calculate a Boltzmann sampler for it using symbolic linear algebra
(or non-symbolic linear algebra if you fix the parameter up front).

The similarity of this paper to~\cite{DBLP:journals/dam/FlajoletGT92} is probably not accidental given that they have an author in common---both
are about using generating functions of regular languages to simplify some natural probabilistic problem through semi-automatic constructions.

\section{Misc Notes}

The Boltzmann Samplers were motivated because they were easy to construct,
but there's another reason to consider them:
They are the maximum entropy distribution over \(\mathcal{L}\) with a given expected size.

From \href{https://en.wikipedia.org/wiki/Maximum_entropy_probability_distribution#Discrete_version}{Wikipedia's entry on Maximum Entropy Distributions}:

\begin{theorem}
Let \(S = \{x_1, \ldots, \}\) be some countable set (possibly finite) and let \(f: S \to \mathbb{R}\).
Let \(f_i: S \to \mathbb{R}\), \(a_i \in \mathbb{R}\) and let \(C\) be the class of random variables \(X\) over \(S\) which satisfy \(E(f_i(X)) = a_i\).

Then if \(C\) contains an element which assigns strictly positive probability to each \(x_i\), and \(C\) also contains a maximum entropy distribution,
then that distribution must take the form \(P(X = x) = c \exp\left( \sum \lambda_i f_i(x)  \right)\) for appropriately chosen constants \(c, \lambda_i\) to achieve the desired constraints and make the probabilities add up to one.

Morever, if such a choice of \(c, \lambda_i\) exists, then the distribution is always the maximum entropy distribution.
\end{theorem}

\begin{corollary}
The maximum entropy distribution over any combinatorial class with a given expected size is a Boltzmann Sampler.
\end{corollary}

\section{Boltzmann Sampling over Possibly Infinite Unknown Automata}

Note for those who are following along at home:
This chapter is basically stream of consciousness.

Suppose we have some automaton with a finite alphabet \(\mathcal{A}\) and states \(S = \{s_0, \ldots, s_n, \ldots\}\) which may or may not be finite.
We have a single origin state \(s_0\),
a transition function \(\delta: \mathcal{A} \times \mathcal{S} \to \mathcal{S}\),
an an acceptance function \(a: S \to \{0, 1\}\).
This defines a language \(\mathcal{L}\) over \(\mathcal{A}\) in the usual way:
Start at \(s_0\), repeatedly move to the next state via the next character of the string,
if at the end we're in an accepting state the string is in the language.
Similarly each of the states defines the language \(\mathcal{L_i}\) of suffixes starting from that state,
with \(\mathcal{L} = \mathcal{L}_0\).

Let \(f_i\) be the Boltzmann generating function for \(\mathcal{L}_i\).
If we knew these exactly,
we could calculate a Boltzmann sampler for \(\mathcal{L}\) by defining the random walk that,
at state \(s_i\),
chooses between terminating (if the state is expected) with weight one,
or emitting \(c\) and transitioning to \(s_j = \delta(c, s_i)\),
with weight \(f_j(x)\).

Unfortunately, we will typically not know these generating functions!
For regular languages it is possible but expensive to calculate them,
but we have to find all of the states up front (of which there may be exponentially many),
and it's moderately expensive in the size.
For context-free languages the problem is uncomputable in general (I think),
and for languages of a completely unknown structure we're certainly stuck.

But with only a little information,
we can actually simulate the Boltzmann sampler fairly efficiently!

Suppose we have lower bounds \(l_i(x)\) and \(u_i(x)\) with \(0 \leq l_i(x) \leq f_i(x) \leq u_i(x)\) for all \(i\).
Suppose additionally we have \(u_i \leq u(x)\).

It is easy to find such bounds in many cases.

A natural choice of \(l_i\) is \(a\)---in an accepting state,
the Boltzmann function contains a \(1\) term for the zero-string.
In an non-accepting state we might not have any strings matching from here at all,
so without more information \(0\) is the best lower bound we can do.

One possible source of lower bound is that if we have some strings \(v_i\) in the language we can walk the graph and then use them to witness some suffixes of \(s_i\),
which will give us a lower bound by adding up the terms corresponding to them.
In general if we know that \(\mathcal{L}_i \supseteq \mathcal{L}'\) with generating function \(f_i'\) then \(l_i(x) = f_i'(x)\) is a suitable choice.

We have three potential sources of upper bounds:

\begin{itemize}
\item If we know that \(\mathcal{L} \subseteq \mathcal{L}'\) then every \(s_i\) is \(\mathcal{L}\)-equivalent to some state in a representation for \(\mathcal{L}'\),
so if we have some uniform upper bound \(A(x)\) on states in \(\mathcal{L}'\) then we also have it for states in \(\mathcal{L}\).
\item \(f_i\) is monotnoic increasing in \(x\), so if we know some upper bound for \(f_i(y)\) with \(y > x\) then we also know it for \(f_i(x)\).
\item If \(x < \frac{1}{|\mathcal{A}|}\) then \(f_i(x) \leq \sum {(x |\mathcal{A}|)}^n = \frac{1}{1 - x |\mathcal{A}|}\).
\end{itemize}

We can now use these bounds to simulate a Boltzmann sampler for any fixed value of \(x\) where \(u_i(x) < \infty\) for all \(i\)!

To do this we maintain \emph{bound tables} for each \(i\).
These are updatable tables such that at any point we guaranteee that \(L[i] \leq f_i(x) \leq U[i]\).
When we first evaluate \(L[i]\) or \(U[i]\),
we automatically initialise them to \(l_i(x), u_i(x)\) respectively.
We also maintain a visited table which tracks if we have ever evaluated \(\delta(c, i)\) (we assume that \(\delta\) is expensive but cached).
Let \(V[i]\) be the set of \(c \in mathcal{A}\) such that we have previously evaluated \(\delta(c, s_i)\).

We can now perform the random walk of a Boltzmann sampler without ever having to fully compute \(f_i(x)\) as follows:

When making a decision about what to do next (stop or transition) we sample as follows:

\begin{itemize}
\item Stopping here gets a weight of \(0\) or \(1\) as normal depending on whether \(s_i\) is an accepting state.
\item For each \(c \in \mathcal{A}\), we give it a weight according to some upper bound on \(f_{\delta(c, s_i)}\).
If we have previously evaluated \(\delta(c, s_i) = s_j\) then this is \(U[j]\).
Otherwise it is \(u(x)\).
If \(u(x) = \infty\) then we can just evaluate \(\delta(c, s_i)\) for each \(c\),
which is more expensive but allows us to never care about infinite weights.
We then draw an action with probability proportional to its weight.
\item If we drew ``stop'' then we stop as normal.
If we drew \(c\), then we determine \(s_j = \delta(c, s_i)\) if we haven't already.
We draw a number \(t\) uniformly at random in \([0, U[j]]\).
If \(t \leq L[j]\) then we emit \(c\) and transition to \(j\).
If \(t > L[j]\) then we call \texttt{improve(j, t)}.
After this call,
we will either have \(L[j] \geq t\),
or \(U[j] < t\).
If the former, transition with \(c\) as before.
If the latter, loop back to step 1 (that is, we stay at the current state but need to re-evaluate what to emit. Note that \(U[j]\) may have changed so we may need to update the sampling process).
\end{itemize}

The fact this this produces the correct result is fairly straightforward:
Conceptually what's happening is that we have numbers \(q_e \geq p_e\),
where \(p_e\) is the true probability of some event.
The probability of a single loop iteration choosing \(e\) is \(\frac{p_e}{q_e} \frac{q_e}{\sum q_{e'}} = \frac{p_e}{\sum q_{e'}}\).
So \(P(e| \text{ no repeat }) = p_e\).

\texttt{improve(i, t)} is a function that is designed to do just enough evaluation of the graph to put both \(L[i]\) and \(U[i]\) on the same side of \(t\).
It does this through a process of iterative refinement of lower bounds,
by using the recurrence relationship \(f_i(x) = a(i) + \sum\limits_{c \in \mathcal{A}} x f_{\delta(c, s_i)}\).

This is monotonic increasing in the values of \(f_{\delta(c, s_i)}\),
so in particular we can update the tables according to the following rules:

\begin{itemize}
\item \(L[i] \leftarrow \max(L[i], a(i) + x \sum\limits_{c \in V[i]} L[\delta(c, i)])\)
\item \(U[i] \leftarrow \min(U[i], a(i) + x \sum\limits_{c \in V[i]} U[\delta(c, i)]) + (|\mathcal{A} - |V[i]|)u(x)\)
\end{itemize}

\begin{proposition}
Once \(|V[i]| = |\mathcal{A}|\) and we have updated \(L[i]\) and \(U[i]\) according to the above rules,
\(U[i] - L[i] \leq x \max\limits_{s_j = \delta(c, s_i)} (U[j] - L[j])\).
In particular, \(U[i] - L[i] \leq x u(x)\).
\end{proposition}

I'm not sure of exactly the best way to get this process to converge at this point.
If you get the bound down to \(U[i] - L[i] < \epsilon\) then this halts the process with probability \(1 - \epsilon\),
but the question is how to get the bound down most efficiently?

Evaluating all states reachable in \(n = \lceil\frac{\log \epsilon - \log u(x)}{\log x}\rceil\) steps will achieve that.
This requires evaluating up to \(|\mathcal{A}|^n\) states,
although hopefully it wouldn't typically be that many in practice.

Ideas for improving it:

\begin{itemize}
\item We know how to handle self-loops perfectly, so we should use that.
\item Possibly this might be better phrased in terms of \(\frac{L[i]}{U[i]}\)?
That is the desired quantity to maximize, but it's less naturally expressed in terms of its children.
\item Use a greedy algorithm that just repeatedly tries to halve \(U[i] - L[i]\) by updating it,
evaluating as many unevaluated transitions as it needs, and recursing (avoiding loops) to the child with the largest contribution to its gap.
\end{itemize}

Idea:

Measure the ``overspill'', where \(o(i) = 1 - \frac{L[i]}{U[i]}\), or \(0\) if \(U[i] = 0\).
This is the probability of having to improve the bounds when sampling into state \(i\).

\(o(i) \leq \epsilon\) if and only if \(L[i] \geq (1 - \epsilon)U[i]\).

If \(L, U\) have been updated as above (along with the fix for self-reference),
suppose \(o(j) \leq \epsilon\) for every \(j\) immediately reachable from \(i\),
we can use this to bound \(o(i)\).
First assume \(i\) is not accepting:

\begin{align*}
o(i) &= 1 - \frac{x \sum L[\delta(c, i)]}{x \sum U[\delta(c, i)]} \\
&\leq 1 - \frac{x (1 - \epsilon) \sum U[\delta(c, i)]}{x \sum U[\delta(c, i)]} \\
&= \epsilon\\
\end{align*}

Now suppose \(i\) is accepting.
Let \(T = \sum \sum U[\delta(c, i)]\)

\begin{align*}
o(i) &= 1 - \frac{1 + x \sum L[\delta(c, i)]}{1 + x \sum U[\delta(c, i)]} \\
&\leq 1 - \frac{1 + x (1 - \epsilon) \sum U[\delta(c, i)]}{1 + x \sum U[\delta(c, i)]} \\
&= 1 - \frac{1 + x (1 - \epsilon) T}{1 + x T}\\
&= \frac{1 + x T - (1 + x (1 - \epsilon) T)}{1 + T}\\
&= \frac{x T - x T + \epsilon x T}{1 + T}\\
&= \epsilon \frac{x T}{1 + x T}\\
&\leq \epsilon \min(1, xT)\\
\end{align*}

So when \(xT\) is small,
we get a much tighter bound on the values for accepting nodes.

\begin{proposition}
Let \(f_i(x) = \sum\limits_{k \geq 0} C_k x^k\).
Then \(f_i(x) - \sum\limits_{k = 0}^n C_k x^k \leq {(|\mathcal{A}|x)}^{n + 1} u(x)\).
\end{proposition}

\begin{proof}
A string in the language is either of length \(\leq n\),
and thus appears in the first \(n\) terms,
or is exactly \(n + 1\) characters followed by the language of some state.
We thus have the remainder as \(\sum\limits_{|w| = n + 1} x^{n + 1} f_{\delta(w, s_i)} \leq {(|\mathcal{A}|x)}^{n + 1} u(x)\) as desired.
\end{proof}

We can also use this to look for probabilistic lower bounds if we're willing to approximate (which we probably should be).
If \(i\) is not accepting and for \(k \leq n\) the probability of a random string of length \(k\) being in \(\mathcal{L}_i\) is at most \(p\),
then we must have \(C_k \leq p |\mathcal{A}|^k\).
This then gives us an upper bound on the initial polynomial of \(p x |\mathcal{A}| \frac{{x |\mathcal{A}|}^n - 1}{x |\mathcal{A}| - 1}\).

This idea turned out to be horribly misleading!

The problem is that although low overspill guarantees that you will fairly accurately pick \(i\) when you draw \(i\),
getting to low overspill is not what you need to get out of the loop iteration!
It may well be that the true value is \(0\) but the initial estimate of the upper bound is really large.
We will \emph{never} get the overspill low unless we manage to prove the upper bound is \(0\),
but we don't need to---we just need to get the upper bound below the value we drew.

Here's an idea that might be worth pursuing:
The idea is that either the problem ``find the shortest path to an accepting state'' is mostly tractable or \emph{everything} we could do is hard.

Idea! Rather than having a generic \(u(x)\),
let's make this more concrete.

Given a language \(\mathcal{L}\) define the \emph{growth} of the langauge as \(g(\mathcal{L}) = \lim\sup \frac{\log |\{x \in \mathcal{L}: |x| = n\}|}{n}\).
Necessarily the growth is at most \(|\mathcal{A}|\).
i.e. \(g(\mathcal{L}) \leq h\) iff asymptotically \(|\{x \in \mathcal{L}: |x| = n\}| \leq h^n\).

The Boltzmann generating function is defined for any \(x < \frac{1}{g(\mathcal{L})}\) and undefined for any \(x > \frac{1}{g(\mathcal{L})}\).

Necessarily the languages of growth at most \(h\) are closed under differentiation:
If not, the set of strings starting with the differentiated prefix would eventually come to dominate the growth.

Actually, this is all needlessly complicated,
and the solution here is the usual best solution:
Make someone else do all the work.
In this case by doing linear programming.

We maintain a subset of the infinite set of linear constraints as follows:
For each node associate LP variables \(v_i\).
The LP is:

\begin{enumerate}
\item \(v_i \leq U[i]\)
\item \(v_i \geq L[i]\)
\item \(v_i - x \sum\limits_c v_{\delta(i, c)} = a(i)\)
\end{enumerate}

At any given time we track only a subset of the equality constraints.
Say a node is \emph{active} if it is the \(v_i\) term in the current LP.\ 

We can now define an iterative process \texttt{improve(i)} as follows:

Initially, we activate \(i\).
We now repeatedly perform the following operations:

\begin{enumerate}
\item Solve the current LP with \(\min v_i\).
Set \(L[i]\) to its result.
Activate the currently inactive \(j\) with the highest shadow price on its constraints.
If no such \(j\) exists,
we must have an exact LP.\ 
Set \(U[i] = L[i]\) and stop.
\item Repeat the above with \(U[i] = \max v_i\)
\end{enumerate}

This process should eventually terminate if the problem is well-posed:
Eventually it will explore all nodes within distance \(k\) of \(i\) (because they should have higher shadow prices!),
and after that point we know \(f_i\) to its first \(k\) terms.

When it does we might as well run the LP a number of final times for each active node to update their minimum and maximum values as well so as to not have to do the slow exploration process each time in future.

Also maybe the shadow price approach is needlessly clever?
What if we just always add in the fringe.

\section{Boltzmann Sampling of Unknown PRNG Languages}

Basic idea:

\begin{definition}
A PRNG language over some alphabet \(\mathcal{A}\) (typically \(\{0, \ldots, 255\}\)) is a prefix-free language \(\mathcal{L}\) with the property that every finite string \(s\) either \(st \in \mathcal{L}\) for some \(t\) or \(s = wt\) for some \(w \in \mathcal{L}\).
\end{definition}

Intuitively these are the strings read by some randomized function in its execution,
where we require the randomized function to have the property that it always has a non-zero probability of terminating.

The Boltzmann Sampler of parameter \(\frac{1}{|\mathcal{A}|}\) corresponds to the operation of reading a uniform infinite string and taking its prefix from the language.
However, this may not be well defined!

Constructing a Boltzmann Sampler for such a language can thus be thought of as ``taming'' unbounded random generators,
as they will be well defined for any \(x < \frac{1}{|\mathcal{A}|}\) while sharing many of the same properties---in
particular being uniformly distributed among anything with the same size.

I'm considering the following algorithm:

\begin{itemize}
\item Run enough of the normal random sampler through L* to get a good (lazy!) DFA for the language.
\item Simulate a Boltzmann Sampler for that language.
\end{itemize}

The core question is basically how accurate that Boltzmann Sampler is after some amount of L*.
We can correct the Boltzmann Sampler whenever it gets it wrong,
but we don't necessarily expect that to improve matters enough---it will improve the automaton to reject more strings,
but that won't necessarily cause it to accept more strings.

One thing that might help is the idea of a \emph{terminating sequence}.

\begin{definition}
A terminating sequence for a language \(\mathcal{L}\) is a (possibly infinite) sequence \(t \in \mathcal{A}^{\leq \omega}\) such that for any word \(w \in  \mathcal{A}^{\leq \omega}\), \(wt\) starts with a word of \(\mathcal{L}\).
\end{definition}

\begin{theorem}
Every PRNG language has a terminating sequence.
If the PRNG language is represented by a finite automaton of size \(n\) then it has a terminating sequence of length at most \(\frac{n(n - 1)}{2}\).
\end{theorem}

\begin{proof}
Let \(w_1, \ldots, w_n, \ldots\) be some enumeration of \(\mathcal{A}^{\leq \omega}\) and define \(t_n\) as follows:

\(t_0 = \epsilon\).
If \(w_n t_{n - 1}\) starts with some string in \(\mathcal{L}\),
\(t_n = t_{n - 1}\).
Otherwise,
because \(\mathcal{L}\) is a PRNG language,
\(w_n t_{n - 1} s \in \mathcal{L}\) for some \(s\).
Let \(t_n = t_{n - 1} s\).

Now define \(t\) as the ``limit'' of the \(t_n\):
If this process is eventually constant, \(t\) is just that constant value.
Otherwise \(t\) is an infinite sequence where \(t_i = {(t_n)}_i\) for sufficiently large \(n\).

If \(\mathcal{L}\) is regular we can use this process to construct a terminating sequence of size \(n^2\):
We only need to enumerate strings leading to each non-terminal state,
so there are only \(n - 1\) of them.
Order them as \(s_0, \ldots, s_n\) in order of increasing length of shortest path from the terminal state (so \(s_0\) is that state).
Necessarily the shortest path from \(s_i\) to the terminal state is at most \(i\)---if not it could not reach any state closer to it,
and so there is no extension of it in the language (contradicting that this is a PRNG language).
Thus we can construct our \(t_i\) above so that \(t_{i + 1} \leq t_i + i\),
and so the final length is \(t_n \leq \sum\limits_{i = 0}^{n - 1} i = \frac{n(n - 1)}{2}\)

\end{proof}

The bound \(\frac{n(n - 1)}{2}\) is tight if \(|\mathcal{A}| \geq n\):
Let \(a_i\) be some enumeration of the alphabet and \(s_i\) some enumeration of the states with \(s_n\) the terminal state.
Define transitions such that \(a_i\) causes \(s_i\) to transition to \(s_{i + 1}\) and for \(j \neq i\),
\(a_j\) causes \(s_i\) to transition to \(s_1\).

Note: In Hypothesis we assume that \(t = 0\ldots\) is a terminating sequence.

(I haven't actually checked that this works, but I'm pretty sure it does).

If we can efficiently find the initial prefix of some infinite sequence in the language (we typically can) we can use terminating sequences to do a sort of large fan-out version of L*,
where instead of classifying a string based on whether \(se \in \mathcal{L}\) we define the function \(f(s) = |w| - |s|\) where \(w\) is the unique prefix of \(st\) that is in \(\mathcal{L}\).
We then distinguish two states with respect to an experiment if \(f(se) \neq f(s'e)\).
This will tend to give us a very accurate picture of the automaton!

We can even do this if \(t\) isn't really a terminating sequence as long as it has a decent chance of terminating any string,
if we have an easy way of determining \(f_m(x) = \min(f(x), m)\) (which, again, we usually do).

For many PRNG languages this likely allows us to determine a perfect representation of the automaton without ever requiring a counter-example!

